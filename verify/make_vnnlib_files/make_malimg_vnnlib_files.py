'''
Make vnnlib files for malimg dataset using nnenum
'''

import sys
import time
from pathlib import Path

import onnx
import onnxruntime as ort

import numpy as np

from nnenum.onnx_network import load_onnx_network
from nnenum.network import nn_flatten

from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
import os
import sys
import csv
from torch.utils.data import Dataset
import tqdm

def load_unscaled_images(filename, specific_image=None, epsilon=0.0):
    '''read images from csv file

    if epsilon is set, it gets added to the loaded image to get min/max images
    '''

    image_list = []
    labels = []

    line_num = 0

    mnist = 'mnist' in filename

    with open(filename, 'r') as f:
        line = f.readline()
                    
        while line is not None and len(line) > 0:
            line_num += 1

            if specific_image is not None and line_num - 1 != specific_image:
                line = f.readline()
                continue
            
            parts = line.split(',')
            labels.append(int(parts[0]))

            if mnist:
                line_list = [int(x.strip())/255.0 for x in parts[1:]]

                # add epsilon
                for i, val in enumerate(line_list):
                    line_list[i] = max(0.0, min(1.0, val + epsilon))
                
                image = np.array(line_list, dtype=np.float32)

                image.shape = (1, 1, 64, 64)

            image_list.append(image)

            line = f.readline()

    return image_list, labels

def make_init_box(min_image, max_image):
    'make init box'

    flat_min_image = nn_flatten(min_image)
    flat_max_image = nn_flatten(max_image)

    assert flat_min_image.size == flat_max_image.size

    box = list(zip(flat_min_image, flat_max_image))
        
    return box

def make_init(nn, image, label, epsilon, vnnlib_name):
    'returns list of (image_id, image_data, classification_label, init_star_state, spec)'
    # make min image, max_image
    min_image = np.clip(image - epsilon, 0, 1)  # Ensure values are within [0, 1] after subtraction
    max_image = np.clip(image + epsilon, 0, 1)  # Ensure values are within [0, 1] after addition

    with open(vnnlib_name, 'w') as f:
        output = nn.execute(image)
        flat_output = nn_flatten(output)

        num_outputs = flat_output.shape[0]
        label = np.argmax(flat_output)

        if label == label:
            # correctly classified
            init_box = make_init_box(min_image, max_image)

            # f.write(f"; GNN benchmark image {image_id + 1} with epsilon = {epsilon}\n\n")

            for i in range(len(init_box)):
                f.write(f"(declare-const X_{i} Real)\n")

            f.write("\n")
                
            for i in range(25):
                f.write(f"(declare-const Y_{i} Real)\n")

            f.write("\n; Input constraints:\n")

            for i, (lb, ub) in enumerate(init_box):
                f.write(f"(assert (<= X_{i} {ub:.18f}))\n")
                f.write(f"(assert (>= X_{i} {lb:.18f}))\n\n")

            f.write("\n; Output constraints:\n")
            f.write("(assert (or\n")

            for i in range(num_outputs):
                if i == label:
                    continue

                f.write(f"    (and (>= Y_{i} Y_{label}))\n")

            f.write("))")

# def load_data(datapath, imsize, batch_size):
#     """
#     Load malimg dataset. 
#     """
#     transform = transforms.Compose([
#         transforms.Grayscale(),
#         transforms.ToTensor(),
#         # transforms.Resize((imsize, imsize), antialias=True),
#     ])

#     test_dataset = datasets.ImageFolder(root=datapath, transform=transform)

#     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

#     return test_loader


class MalimgDataset(Dataset):
    def __init__(self, root, csv_file, transform=None):
        """
        Custom dataset that includes only the images listed in the CSV file.
        """
        self.transform = transform = transforms.Compose([
            transforms.Grayscale(),
            transforms.ToTensor(),
        ])

        # Read the CSV file and get a list of image paths
        with open(csv_file, newline='') as file:
            reader = csv.reader(file)
            self.listed_images = set(next(reader))  # Use a set for faster search
            self.listed_images = [f.replace("../../../", "") for f in self.listed_images]

        # Load the full dataset
        self.full_dataset = datasets.ImageFolder(root=root)
        self.filtered_samples = [s for s in self.full_dataset.samples if s[0] in self.listed_images]


    def __len__(self):
        return len(self.filtered_samples)

    def __getitem__(self, idx):
        path, label = self.filtered_samples[idx]
        image = self.full_dataset.loader(path)
        if self.transform:
            image = self.transform(image)
        
        return np.array(image.unsqueeze(0), dtype=np.float32), np.array(label)

def main():
    'main entry point'
    # csv path
    csv_path = 'archive/malimg_verification_image_paths.csv'
    # Dataset
    dataset = MalimgDataset("archive/malimg_dataset/validation_resize", csv_path)

    onnx_filename = 'models/malimg/malware_malimg_family_scaled_4-25.onnx'  # Replace with your model path
    epsilons = [1, 2, 3]

    #nn = load_onnx_network(onnx_filename)
    #print(f"loading onnx network from {onnx_filename}")
    nn = load_onnx_network(onnx_filename)
    print(f"loaded network with {nn.num_relu_layers()} ReLU layers and {nn.num_relu_neurons()} ReLU neurons")
    # test_loader = load_data(datapath="archive/malimg_dataset/validation_resize", imsize=64, batch_size=32)
    # imgs, labels = next(iter(test_loader))
    # indx = 1

    # img_1 = imgs[0].unsqueeze(0)
    # img_1 = np.array(img_1, dtype=np.float32)

    # out = nn.execute(img_1)
    # label_1 = np.array(labels[0])
    os.makedirs("vnnlib/malimg", exist_ok=True)
    for e in epsilons:
        print(f"Making {e} files ...")
        for i in range(len(dataset)):
            if i % 10 == 0:
                print(f"img {i}/{len(dataset)}")
            img, label = dataset[i]
            vnnlib_name = f"vnnlib/malimg/malimg_{e}_{i}.vnnlib"
            specific_image = None
            print("Image ", i)
            tup_list = make_init(nn, img, label, e/255, vnnlib_name)

if __name__ == '__main__':
    main()
 