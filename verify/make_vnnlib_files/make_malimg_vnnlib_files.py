'''
Make vnnlib files for malimg dataset using nnenum
'''

import sys
import time
from pathlib import Path
import onnx
import onnxruntime as ort
import numpy as np
from nnenum.onnx_network import load_onnx_network
from nnenum.network import nn_flatten
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
import os
import sys
import csv
from torch.utils.data import Dataset
import tqdm

def make_init_box(min_image, max_image):
    'make init box'

    flat_min_image = nn_flatten(min_image)
    flat_max_image = nn_flatten(max_image)

    assert flat_min_image.size == flat_max_image.size

    box = list(zip(flat_min_image, flat_max_image))
        
    return box

def make_init(nn, image, label, epsilon, vnnlib_name):
    """
    Makes a vnnlib file of image and epsilon.
    """
    # make min image, max_image
    min_image = np.clip(image - epsilon, 0, 1)  # Ensure values are within [0, 1] after subtraction
    max_image = np.clip(image + epsilon, 0, 1)  # Ensure values are within [0, 1] after addition

    with open(vnnlib_name, 'w') as f:
        output = nn.execute(image)
        flat_output = nn_flatten(output)

        num_outputs = flat_output.shape[0]
        label = np.argmax(flat_output)

        if label == label:
            # correctly classified
            init_box = make_init_box(min_image, max_image)

            for i in range(len(init_box)):
                f.write(f"(declare-const X_{i} Real)\n")

            f.write("\n")
                
            for i in range(25):
                f.write(f"(declare-const Y_{i} Real)\n")

            f.write("\n; Input constraints:\n")

            for i, (lb, ub) in enumerate(init_box):
                f.write(f"(assert (<= X_{i} {ub:.18f}))\n")
                f.write(f"(assert (>= X_{i} {lb:.18f}))\n\n")

            f.write("\n; Output constraints:\n")
            f.write("(assert (or\n")

            for i in range(num_outputs):
                if i == label:
                    continue

                f.write(f"    (and (>= Y_{i} Y_{label}))\n")

            f.write("))")


class MalimgDataset(Dataset):
    def __init__(self, root, csv_file, transform=None):
        """
        Custom dataset that includes only the images listed in the CSV file.
        """
        self.transform = transform = transforms.Compose([
            transforms.Grayscale(),
            transforms.ToTensor(),
        ])

        # Read the CSV file and get a list of image paths
        with open(csv_file, newline='') as file:
            reader = csv.reader(file)
            self.listed_images = set(next(reader))  # Use a set for faster search
            self.listed_images = ["../../" + f for f in self.listed_images]

        # Load the full dataset
        self.full_dataset = datasets.ImageFolder(root=root)
        self.filtered_samples = [s for s in self.full_dataset.samples if s[0] in self.listed_images]


    def __len__(self):
        return len(self.filtered_samples)

    def __getitem__(self, idx):
        path, label = self.filtered_samples[idx]
        image = self.full_dataset.loader(path)
        if self.transform:
            image = self.transform(image)
        
        return np.array(image.unsqueeze(0), dtype=np.float32), np.array(label)

def main():
    """
    main entry point
    """
    # csv path
    csv_path = '../../archive/malimg_verification_image_paths.csv'
    data_path = "../../archive/malimg_dataset/validation_resize"
    # Dataset
    dataset = MalimgDataset(data_path, csv_path)

    onnx_filename = '../../models/malimg/malware_malimg_family_scaled_4-25.onnx'  # Replace with your model path
    epsilons = [1, 2, 3]

    nn = load_onnx_network(onnx_filename)
    print(f"loaded network with {nn.num_relu_layers()} ReLU layers and {nn.num_relu_neurons()} ReLU neurons")

    os.makedirs("../../vnnlib/malimg", exist_ok=True)
    for e in epsilons:
        print(f"Making {e} files ...")
        for i in range(len(dataset)):
            if i % 10 == 0:
                print(f"img {i}/{len(dataset)}")
            img, label = dataset[i]
            vnnlib_name = f"../../vnnlib/malimg/malimg_{e}_{i}.vnnlib"
            specific_image = None
            print("Image ", i)
            tup_list = make_init(nn, img, label, e/255, vnnlib_name)

if __name__ == '__main__':
    main()
 