"""
Script to test trained BODMAS binary malware classifiers with pytorch.


NOTES:
models = [none-2, 4-2, 16-2]
"""

import argparse
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import matplotlib as mpl
import numpy as np
import torch
import sys
from sklearn.preprocessing import StandardScaler
import os
import seaborn as sns
from sklearn import metrics
from train_bodmas_pytorch import SimpleNN
import re

sns.set_theme()

DATAPATH = '../../archive/bodmas.npz'
SAVEDIR = "../../models/bodmas"
SEED = 14

np.random.seed(SEED)
torch.manual_seed(SEED)


def get_args():
    """
    Parse Arguments.
    """
    parser = argparse.ArgumentParser()
    parser.add_argument("-d", "--datapath", type=str, default=DATAPATH)
    parser.add_argument("--savedir", type=str, default=SAVEDIR)
    
    args = parser.parse_args()
    return args
    
def load_and_split_data(filename, test_size=0.2, seed=12):
    """
    Load the data from a file, scale it, and split it into training and testing sets.

    :param filename: The path to the file containing the data.
    :param test_size: The proportion of the dataset to include in the test split.
    :param seed: The seed for random number generation.

    :return: Tensors X_train, X_test, y_train, y_test.
    """
    #
    # Load and scale data
    #
    scaler_standard = StandardScaler()
    data = np.load(filename)

    X = data['X']  # all the feature vectors
    y = data['y']  # labels, 0 as benign, 1 as malicious
    #
    # Scale data
    #
    scaler_standard.fit(X)
    X_scaled = scaler_standard.transform(X)
    #
    # Split the data
    #
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=seed)
    #
    # Convert to PyTorch tensors
    #
    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
    y_train_tensor = torch.tensor(y_train, dtype=torch.long)
    y_test_tensor = torch.tensor(y_test, dtype=torch.long)

    return X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor

def extract_number(name):
    """
    Extract hidden layers from file name using regex.

    :param name: file name which includes the hidden layers

    :return: int
    """
    #
    # Regular expression pattern to match the number before '-2'
    #
    pattern = r"_([0-9]+)-2"
    #
    # Search for the pattern in the string
    #
    match = re.search(pattern, name)
    #
    # Extract and return the number if found
    #
    if match:
        return int(match.group(1))  # Convert to int for numerical value
    else:
        return None  # Or raise an error, if appropriate

def load_pytorch_model(model_path, input_size):
    """
    Load a pretrained pytorch model. 
    """
    if "none" in model_path:
        model = SimpleNN(input_size=input_size, hidden_size=0)  # Replace with your actual model class
    else:
        hidden = extract_number(model_path)
        model = SimpleNN(input_size=input_size, hidden_size=hidden)
        
    model.load_state_dict(torch.load(model_path))
    model.eval()
    return model
    

def test_classifier(X_test, y_test, args):
    #
    # Create Save directory
    #
    if os.path.exists("results") == 0:
        os.mkdir("results")
    #
    # Load Models
    #
    print("\nLoading models ...")
    bodmas_path = f"{args.savedir}/malware_bodmas_binary_scaled_"
    models = ["none-2.pt", "4-2.pt", "16-2.pt"]

    acc = [] # accuracy
    prec = [] # precision
    rec = [] # recall
    f1 = [] # f1

    dec = 2 # decimal point values

    # Evaluating the test set
    for i, model_name in enumerate(models):
        model = load_pytorch_model(bodmas_path+model_name, input_size=X_test.shape[1])
        print("Testing Model: ", i)

        # Forward pass
        outputs = model(X_test)
        _, predicted = torch.max(outputs.data, 1)

        # Calculate metrics
        accuracy = metrics.accuracy_score(y_test.numpy(), predicted.numpy())
        precision = metrics.precision_score(y_test.numpy(), predicted.numpy())
        recall = metrics.recall_score(y_test.numpy(), predicted.numpy())
        f = metrics.f1_score(y_test.numpy(), predicted.numpy())

        # Append metrics
        acc.append(round(accuracy, dec))
        prec.append(round(precision, dec))
        rec.append(round(recall, dec))
        f1.append(round(f, dec))

    # reorg for plot
    none_2_stats = [acc[0], prec[0], rec[0], f1[0]] 
    four_2_stats = [acc[1], prec[1], rec[1], f1[1]] 
    six10_2_stats = [acc[2], prec[2], rec[2], f1[2]]
    #
    # Write to Txt files
    #
    with open("results/Table_4_bodmas.txt", "w") as f:
        f.write("Model | Accuracy | Precision | Recall | F1\n")
        f.write("--------------------------------------------\n")
        for m, s in zip(["none-2", "4-2", "16-2"], [none_2_stats, four_2_stats, six10_2_stats]):
            st = ""
            for i in range(len(s)):
                st += " & " + str(s[i])
            f.write(m + st + "\n")
    print("Test results saved to: results/Table_4_bodmas.txt")
        
        
    print("\nFinished Testing!")
    
if __name__ == "__main__":
    #
    # Get and validate arguments
    #
    args = get_args()
    #
    # Generate Testing Set
    #
    print("\nLoading Data ...")
    X_train, X_test, y_train, y_test = load_and_split_data(args.datapath, test_size=0.2, seed=SEED)
    #
    # Test
    #
    print("------- Testing ------------")
    test_classifier(X_test, y_test, args)